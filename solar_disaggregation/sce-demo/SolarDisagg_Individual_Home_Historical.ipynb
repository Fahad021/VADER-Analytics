{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform historical solar disaggregation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "# import ipy_autoreload\n",
    "from copy import deepcopy\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import CSSS\n",
    "import datetime as dt\n",
    "import pickle as pk\n",
    "from imp import reload\n",
    "import copy\n",
    "from time import time as t_clock\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "from SolarDisagg import createTempInput, createSolarDisaggIndvInputs\n",
    "from utilities import Setup_load as SetUp_load\n",
    "import math\n",
    "import pprint\n",
    "from Custom_Functions.error_functions import cv_pos,rmse_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "determining sites with full data...\n",
      "querying load and generation data...\n"
     ]
    }
   ],
   "source": [
    "Setup_load = deepcopy(SetUp_load())\n",
    "Setup_load.QueryOrLoad('11-01-2016','01-10-2017')#(start_date = '01-01-2015', end_date = '01-10-2017')\n",
    "load_data, load_data_2, weather, grouped_data, ids, solar_ids, homeids  = Setup_load.load_setup()\n",
    "load_data_2['temperature'] = weather['temperature']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove those solar houses that have generation = 0 for continous N_obs.\n",
    "N_obs_day = 96 # number of observations in one day.\n",
    "N_obs = 3*N_obs_day\n",
    "remove = []\n",
    "for i in solar_ids['solar']:\n",
    "    df = grouped_data.get_group(i)\n",
    "    roll_mean = df.gen.rolling(N_obs).mean()\n",
    "    if np.nansum(roll_mean < 0.001) > 0:\n",
    "        remove.append(i)\n",
    "len(remove)\n",
    "\n",
    "## Update the data accordingly\n",
    "ids = list(set(ids) - set(remove))\n",
    "load_data = load_data[~load_data['dataid'].isin(remove)]\n",
    "load_data_2.swaplevel(axis = 1).drop(remove,axis = 1, inplace = True)\n",
    "solar_ids['solar'] = list(set(solar_ids['solar']) - set(remove))\n",
    "solar_ids['nosolar'] = list(set(solar_ids['nosolar']) - set(remove))\n",
    "grouped_data = load_data.groupby(\"dataid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do a quick plot of load data\n",
    "df = deepcopy(grouped_data.get_group(solar_ids['solar'][0]))\n",
    "np.random.seed(9)\n",
    "start = np.random.choice(range(len(df)))\n",
    "df.iloc[start:start+2*96,1:].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = deepcopy(load_data_2)\n",
    "# np.random.seed(56)\n",
    "\n",
    " ## Choose homes and proxies\n",
    "proxy_ids = list(np.random.choice(solar_ids['solar'],1))\n",
    "tune_ids = list(np.random.choice(solar_ids['solar'],1))\n",
    "if not tune_ids:\n",
    "    tune_ids = proxy_ids\n",
    "home_ids = list(np.random.choice(ids,20,replace = False)) + tune_ids\n",
    "\n",
    "# pd.to_datetime('01-09-2019')\n",
    "n_days = 30 # number of days to analyse\n",
    "resolution_minutes = (df.index[1]-df.index[0]).seconds/60 # determine the resolution of the data\n",
    "time_index = [df.index[0],df.index[min(len(df.index)-1,int(24*60/resolution_minutes*n_days))]] # beginiing and end datetime of the window to analyse\n",
    "index_time = df.index[(df.index >= time_index[0]) & (df.index <= time_index[1])] # index useful to plot later\n",
    "\n",
    " ## Creating the data for ingestion in Solar Disagg\n",
    "data = createSolarDisaggIndvInputs(df, home_ids, solar_proxy_ids= proxy_ids, time_index = time_index)\n",
    "# pprint.pprint(data, indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solar disaggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Initial model\n",
    "reload(csss.SolarDisagg)\n",
    "sdmod0 = deepcopy(csss.SolarDisagg.SolarDisagg_IndvHome(**data))\n",
    "sdmod0.constructSolve(solver = None) # if solver = None, it uses the default one\n",
    " ## Adding tuning system generation\n",
    "for key in tune_ids:\n",
    "    sdmod0.addTrueValue(-df['gen'][key].loc[index_time], str(key))\n",
    " ## update the alpha weights and perform the disaggregation\n",
    "sdmod0.fitTuneModels(list(map(str,tune_ids)))\n",
    "sdmod0.tuneAlphas()\n",
    "sdmod0.constructSolve(solver = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_homes = len(home_ids)\n",
    "n_pts = len(index_time) # number of points to plot\n",
    "fig, ax = plt.subplots(nrows= n_homes, ncols=1, sharex=True, figsize=(16,1.5*n_homes)) # n_pts/96*1.5\n",
    "for i in range(n_homes):\n",
    "    idd = str(home_ids[i])\n",
    "    ax[i].plot(index_time,-sdmod0.models[idd]['source'].value[0:n_pts], label = 'gen_'+idd)\n",
    "    ax[i].plot(index_time,df['gen'][int(idd)].loc[index_time].values[:n_pts], label = 'true_'+idd)\n",
    "    ax[i].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig('figures/example_solar_disag_3months_px.png')\n",
    "# Calculate the estimated SNR for the non solar houses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the error metric\n",
    "metrics = ['cv_pos','rmse_pos'] ## _pos refer to the fact that the performance metrics are calculated when the actual power (or the predicted power in case of non solar houses) is greater than 5% of its average. \n",
    "errors = pd.DataFrame(index = home_ids, columns = metrics)\n",
    "for idd in home_ids:\n",
    "    errors.loc[idd] = cv_pos(np.array(-sdmod0.models[str(idd)]['source'].value).squeeze(),df['gen'][int(idd)].loc[index_time].values),rmse_pos(np.array(-sdmod0.models[str(idd)]['source'].value).squeeze(),df['gen'][int(idd)].loc[index_time].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
